---
title: "hydro_climate_trends"
author: "Nick Gubbins"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# Load packages.
library(here)
library(tidyverse)
library(ggplot2)
library(naniar)
library(lubridate)
library(feather)
library(macrosheds)
library(moments)
library(feather)
library(lfstat)
library(trend)
library(ggrepel)
library(ggthemes)

# Set directory to folder containing new data.
my_ms_dir <- "data_raw"

# fix package calls while using v2 ahead of release
#remove this if using the v2 dataset from the macrosheds package proper
rdata_path <- my_ms_dir
load(file.path(rdata_path, 'ms_site_data.RData'))
load(file.path(rdata_path, 'ms_vars_ws_attr.RData'))
load(file.path(rdata_path, 'ms_vars_ts.RData'))
load(file.path(rdata_path, 'ms_var_catalog.RData'))

nv <- as.environment('package:macrosheds')

for(ms_data in c('ms_vars_ts', 'ms_vars_ws', 'ms_site_data', 'ms_var_catalog')){
    unlockBinding(ms_data, nv)
    assign(ms_data, get(ms_data), envir = nv)
    lockBinding(ms_data, nv)
}
```
# Trend detection

## Reading in and summarizing data.

First reading in summary data and work that Heili already did.

```{r}
#from MS
ws_sums <- read_feather(here('data_raw', 'watershed_summaries.feather'))
hydro <- read_feather(here('data_raw', 'spatial_timeseries_hydrology.feather'))
### this next one will take a minute
clim <- read_feather(here('data_raw', 'spatial_timeseries_climate.feather')) %>%
  mutate(year = year(date),
         month = month(date),
        water_year = case_when(month %in% c(10, 11, 12) ~ year+1,
                                TRUE ~ year)) %>%
    select(site_code, date, water_year, var, val) %>%
    pivot_wider(id_cols = c(site_code, date, water_year), 
                names_from = var, values_from = val, values_fn = mean) %>%
    group_by(site_code, water_year) %>%
    summarize(precip_mean_ann = mean(cc_precip_median, na.rm = T),
              precip_total_ann = sum(cc_precip_median, na.rm = T),
              temp_mean_ann = mean(cc_temp_mean_median, na.rm = T)
              )

# From q_metrics script
q_metrics <- readRDS(here('data_working', 'discharge_7metrics_siteyear_082024.rds'))
```
Next, join climate summaries to magnificent 7 from q_metrics script. 

```{r}
com <- q_metrics %>%
    full_join(clim, by = c('site_code', 'water_year'))
```

Perform trend detection at each site.

```{r}
com_long <- pivot_longer(com, cols = -c('site_code', 'water_year'), names_to = 'var', values_to = 'val')

out_frame <- tibble(site_code = as.character(),
                    var = as.character(),
                    start = as.integer(),
                    end = as.integer(),
                    trend = as.integer(),
                    p = as.integer())

for(i in unique(com_long$site_code)) {
    
    target_site <- filter(com_long, site_code == i) 
    
    dat_check <- na.omit(target_site)
    
    if(nrow(dat_check) > 1){
    #loop  through metrics
    for(j in unique(target_site$var)){
        
    target_solute <- filter(target_site, var == j)  %>%
        arrange(water_year) %>%
        na.omit()
        
    if(nrow(target_solute) > 9){ 
    start <- min(target_solute$water_year)
    end <- max(target_solute$water_year)
    n <- nrow(target_solute)
    test <- sens.slope(target_solute$val)
    trend <- test[[1]]
    p <- test[[2]]
    
    
    inner <- tibble(site_code = i,
                    var = j,
                    start = start,
                    end = end,
                    n = n,
                    trend = trend,
                    p = p
                    )
    out_frame <- rbind(out_frame, inner)
    
    diag <- ggplot(target_solute, aes(x = water_year, y = val)) +
            labs(title = paste0(i, ' ', j),
                      caption = paste0('n = ', n))+
            geom_point()+
        theme_few()
    
    quietly(ggsave(plot = diag, filename = here('data_working', 'diag_plots', i, paste0(i,'_',j,'.png')),
           create.dir = T))
    
    
    }else{next} #solute level data avail check
        }# end solute loop
    }else{next} # site level data avail check
} #end site loop

#write_csv(out_frame, file = here('data_working', 'hydro_climate_trends.csv'))
```

# Figure creation

## Trend histograms/density plots

Make kernel density plots for each trend. 

```{r}
trends <- out_frame
#trends <- read_csv(here('data_working', 'hydro_climate_trends.csv'))
trends %>%
    filter(p > 0.05) %>% # sign trends only
ggplot(aes(x = trend))+
    geom_density()+
    facet_wrap(~var, scales = 'free')+
    theme_few()
```
## Scatters

Make scatter plots to put domains in context. Going to pull average each domain for now, will want to pick specific exemplar sites in the near future.


```{r}
#uncomment this if using the v2 dataset from the ms package proper
#ms_site_data <- ms_load_sites()

context <- com %>%
    left_join(., ms_site_data, by = 'site_code') %>%
    filter(water_year %in% 2000:2009) %>%
    group_by(domain) %>%
    summarize(flow = mean(m1_meanq, na.rm = T),
              temp = mean(temp_mean_ann, na.rm = T),
              precip = mean(precip_mean_ann, na.rm = T))

ggplot(context, aes(x = temp, y = precip, color = domain)) +
    geom_point()+
    geom_label_repel(aes(label = domain),
                  label.size = .1,
                  box.padding   = 0.35, 
                  point.padding = 0.5,
                  segment.color = 'grey50',
                  max.overlaps = 25)+
        theme_few() +
        theme(legend.position = 'none')
```

```{r}
ggplot(context, aes(x = precip, y = flow, color = domain)) +
    geom_point()+
    geom_label_repel(aes(label = domain),
                  label.size = .1,
                  box.padding   = 0.35, 
                  point.padding = 0.5,
                  segment.color = 'grey50',
                  max.overlaps = 25)+
        geom_abline(slope = 1, color = 'red')+
        theme_few() +
        theme(legend.position = 'none')
```


